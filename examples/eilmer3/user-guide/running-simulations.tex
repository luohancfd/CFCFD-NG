% running-simulations.tex
\section{Running simulations}
%
Setting up a simulation is mostly an exercise in writing a text-based 
description of your flow and its bounding geometry.
This \textit{input script} is presented to the preparation program as 
a Python source file, often with the extension ``.py''.
Once you have prepared your flow specification as an input script using your favourite text editor, 
the simulation data is generated by the \texttt{Eilmer3} programs in a number of stages:
\begin{itemize}
\item[1] Create the geometry definition, a grid and the initial flow state.
  For simple to moderately complex geometries, the built-in geometry tools (described later in this manual)
  are adequate.
  For complex geometries, you may find it convenient to import block-structured grids, 
  possibly from a specialized gridding tool such as \texttt{Gridgen} or \texttt{ICEMCFD}.
\item[2] Run the simulation code to produce flow data at subsequent times.
\item[3] Reformat the flow solution data to produce files suitable for a data viewing program such as Paraview or GNU-Plot.
\end{itemize}

\newpage
\subsection{Data preparation (with e3prep.py)}
Create the geometry definition and a grid with the command\\
         \texttt{\$ e3prep.py --job=\textit{job} --do-svg }\\ \index{e3prep.py!using}\index{preparation}
         \vspace{0.25cm} \\
         \centerline{\includegraphics[width=0.7\textwidth]{figs/preparation.pdf}}\\
         The italics word \textit{job} in the command should be replaced 
         by whatever job name that you have chosen.
         That name is then used as a base to derive specific names for each of
         the files associated with the simulation.
         At a minimum, you have an input script called \textit{job}\texttt{.py} 
         with the \texttt{.py} extension, indicating that the script is written in Python.
         The files from the preparation stage are:
         \begin{itemize}
           \item \textit{job}\texttt{.config}: \index{config file}
             A database of configuration parameters in INI format.
             Parameters are specified, one per line, as \textit{parameter-name = value}.
             A hierarchical structure is given to the set of parameters via
             named subsections in the file.
             Although you would probably never assemble one of these parameter files
             from scratch manually, it is sometimes convenient to alter a value or two and rerun
             a simulation without invoking \texttt{e3prep.py}.
           \item \textit{job}\texttt{.control}: \index{control file}
             A small database of parameters to control the time-stepping, the final time,
             and the intervals between writing of solutions and history data.
             The content of this file is also in INI format and it is parsed at the
             start of every $nth$ step, where $n$ is given by the count value in the \texttt{control\_count}
             parameter (default: 10).
             This way, a user can alter the simulation behaviour (by editing this file)
             without having to restart the simulation.
             To stop a simulation cleanly, set the \texttt{halt\_now} entry to 1.\index{halting a simulation}
             Other control parameters are marked with \ddag~ in Section\,\ref{sec:sim-control-parameters}.
           \item  \textit{job}\texttt{.times}:
             A mapping of time stamps to actual times at which the simulation
             data was written.
             After the preparation stage, there should be only the zero-time entry.
           \item \textit{job}\texttt{.svg} or \textit{job}\texttt{.wrl}: \index{SVG} \index{VRML}
             Sometimes it is convenient to see a graphical representation of the flow domain 
             and boundary conditions.
             These options produce a SVG or VRML rendering of the block boundaries 
             and the boundary-condition labels.
             The \texttt{--do-svg} will invoke the rendering of two-dimensional blocks
             to a scalable-vector-graphics file while \texttt{--do-vrml} will render 
             three-dimensional blocks to a virtual-reality-modeling-language file.
             For two-dimensional simulations, the SVG file can be edited in a program such as \texttt{Inkscape}
             (\url{http://www.inkscape.org})
             and the result used as part of your documentation for a particular simulation.
           \item \textit{job}\texttt{.grid.b0000.t0000}, \textit{job}\texttt{.grid.b0001.t0000} :
             The grid of finite-volume cells, 
             one file for each block that defines part of the flow domain.
             The grids are written as plain text files in a relatively simple format.
             The spatial coordinates for points within each file are
             associated with cell vertices of the structured grid.\footnote{Note that, in recent versions of the programs, 
             the grid and flow files are written to subdirectories within the job directory.}
           \item one flow-data file for each block:
             \textit{job}\texttt{.flow.b0000.t0000}, \textit{job}\texttt{.flow.b0001.t0000}, ...
             containing the initial flow state within each of the finite-volume cells.
             Look at the first couple of lines of a flow file to see what data elements are written for each cell.
             Variable names appear on the second line and units are \texttt{SI}.
         \end{itemize}
         Note that the grid and flow data files are written to subdirectories of the same names.
         The grid is written once (at time zero, subdirectory \texttt{grid/t0000/}) and 
         the flow files are written to a new subdirectory (\texttt{flow/tnnnn/}) at each output time.
         This is to keep the main job directory clean and to allow easy copying or moving of 
         individual solution times.
         Also, these files are stored in ``gzip'' format with a ``.gz'' extension by default.\index{gzip}

\subsection{Checking your grid}
%
Before running the simulation code, it is worth checking that your grid has turned out as planned.
Many a simulation has failed to start because its grid was flawed.
Common problems include grids that are twisted or have adjoining blocks with edges that do not match
where they are supposed to be joined.
To get a set of plot files that can be loaded into \verb!Paraview! for examination, use the post-processing program:\\
\texttt{\$ e3post.py --job=}\textit{job}\texttt{ --tindx=0 --vtk-xml} \\
and then pick up the resulting files for inspection with \verb!Paraview!.
Look ahead to Sec.\,\ref{sec:e3post} for a more complete discussion of the postprocessing stage.


\newpage
\subsection{Running the simulation (with e3shared.exe)} 
Run the simulation code to produce flow data at subsequent times.\footnote{If the simulation
finishes too quickly (possibly without taking any steps at all),
it may be that the initial time step size is too large and the calculation is unstable.
One symptom of this is that the final value for \texttt{dt} is reported as being
the excessively large value of \texttt{1e+6} seconds.
Choose a suitably small value and try again.}\\ \index{e3shared.exe!running a simulation}
         \texttt{\$ e3shared.exe --job=\textit{job} --run}\\
         \vspace{0.25cm} \\
         \centerline{\includegraphics[width=0.7\textwidth]{figs/running-sim.pdf}}\\
         The output files are:
         \begin{itemize}
           \item \textit{job}\texttt{.flow.b}\textit{nnnn}\texttt{.t}\textit{mmmm}:
             The flow data for all cells at the times requested.
             As the simulation proceeds, whole-field solutions are written
             to new files with \textit{nnnn} representing the block number and
             \textit{mmmm} representing a time stamp.
             Look up the \textit{job}\texttt{.times} file to see what time values
             belong to each time stamp (or tindx).
             Just as for the grid files, each flow solution file is written 
             as a plain text file with a simple layout, not too different from 
             the Tecplot point-format for a structured-block grid.
             In these files, the spatial coordinates of points within the file are
             associated with the cell centres.
           \item  \textit{job}\texttt{.hist.b}\textit{nnnn}: \index{history location}
             Data at particular ``history locations'' and at times requested.
             This data is typically used to simulate the signals recorded by pressure 
             and heat-transfer sensors mounted on model surfaces.
             When restarting a simulation, the program will append to existing history files 
             rather than clobbering them.
             Note that, if you are running a simulation from the start multiple times, 
             you will need to manually remove the history files before each run.  
             The command \texttt{``rm -r ./hist/''} should do the job.
           \item  \textit{job}\texttt{.times}: \index{times file}
             A mapping of time stamps to actual times at which the simulation
             data was written.
             The main simulation appends lines to this file.
             This file may assist when automating some of the postprocessing operations.
           \item  \textit{job}\texttt{.finish}: \index{finish file}
             An INI-format file giving some information about the time-stepping parameters
             at the end of the simulation.
             These may be useful for starting a follow-on simulation.
         \end{itemize}

\medskip
For viscous simulations, surface heat flux and cell Reynolds number files are also written to the subdirectory \texttt{heat}
if run with the \verb!-q! option.
See the \texttt{--heat-flux-list} option in Section\,\ref{sec:e3post} for a hint at how to extract the data and then
have a look in the data files to see what specific data has been captured. 

\medskip
For reference, here are the hints that are written out when the \verb!--help! option is given on the command line:
{\scriptsize
\begin{verbatim}
$ e3shared.exe --help
Usage: e3shared.exe [OPTION...]
  -f, --job=<job_name>               job_name is typically the same as root_file_name
  -r, --run                          run the main simulation time-stepper
  -t, --tindx=<int>                  start with this set of flow data
  -z, --zip-files                    use gzipped flow and grid files
  -a, --no-zip-files                 use ASCII (not gzipped) flow and grid files
  -q, --heat-flux-files              write heat-flux files
  -s, --surface-files                write surface files
  -v, --verbosity=<int>              set verbosity level for messages
  -w, --max-wall-clock=<seconds>     maximum wall-clock time in seconds
  -m, --mpimap=<mpimap_file>         use this specific MPI map of blocks to rank

Help options:
  -?, --help                         Show this help message
      --usage                        Display brief usage message
\end{verbatim}
} % end scriptsize
\noindent
By default, the starting value for \verb!tindx! will be zero, 
gzipped flow and grid files will be assumed, heat-flux and surface files will not be written,
\verb!verbosity! will be zero (\textit{i.e.} at a minimum), 
and the wall-clock time will not be limited.


\subsection{Running the simulation in parallel (e3mpi.exe)}
%
One can build and run the distributed-memory version of the program, 
\texttt{e3mpi.exe}\index{e3mpi.exe}, on computers with 
the MPI (Message Passing Interface) library\footnote{See, for example, \url{http://www.open-mpi.org/}.} 
and runtime environment.
The notes in Appendix\,\ref{getting-started-file} show how to build and run 
the Eilmer3 executable for OpenMPI.\footnote{These notes are also available in HTML form at the URL
\url{http://cfcfd.mechmining.uq.edu.au/}.}
To run Eilmer3 across multiple processors\index{e3mpi.exe!running a simulation}
on a local machine use the following command\\
\texttt{\$ mpirun -np \textit{n} e3mpi.exe --job=name --run}\\
where \textit{n} is the number of MPI processes to use.
Note that when running the program with these options,
one MPI process is assigned to each block; 
the number of MPI processes \emph{must} match the number of blocks in the simulation.
Each of these MPI processes is a separate program and you may run more than one per core 
or physical processor, however, if you want the shortest calculation time and you had lots of cores,
you would probably run one per core.
For simulations with many blocks, it is sometimes possible to achieve a better balance of
computational load by assigning more than one block to a process.
This is can be done with Eilmer3 by building a mapping file of blocks to MPI processes
(using the \texttt{e3loadbalance.py} program), and then running \texttt{e3mpi.exe} with
the \texttt{--mpimap=} option.\index{mpimap}
The details of using Eilmer3 in this way are described in Appendix~\ref{app:load-balance}. 

\subsection{Running a radiation transport calculation (e3rad.exe)}
% 
The user can build and run the shared-memory version of the radiation transport solver,
\texttt{e3rad.exe}\index{e3rad.exe}, on computers with the OpenMP API.
The notes in Appendix\,\ref{getting-started-file} show how to build and run 
the Eilmer3 radiation transport solver executable for OpenMP.
Note that you should first make the \verb!e3shared! and \verb!e3mpi!, then ``make clean'' 
and, finally, make \verb!e3rad!.

\medskip
You will almost certainly be running \verb!e3rad! in the context of a partly-run flow solution.\\
\verb!$ e3rad.exe  --job=name --tindx=nnnn --run!\\
where \verb!nnnn! is the index of the flow solution for which \verb!e3rad! will update 
the radiation source term.
On output, \verb!e3rad! will have incremented the \verb!tindx! value and written a new set
of data from which the flow solver can restart.


\subsection{Restarting a simulation}\index{restarting a simulation}\index{restart}
\label{sec:restart-sim}
%
By default, the simulation program picks up the flow solution for \texttt{tindx} equal to 0 but
it can be told to pick up any other \texttt{tindx} snapshot.
To pick up a solution and continue, it is probably best to do a little house-keeping\footnote{ 
To support old simulations that terminated with a 9999 solution frame, you can run the postprocessor 
with the command\\
\texttt{\$ e3post.py --job=name --prepare-restart}\\
This renames the 9999 flow files and tidies up the \textit{job}\texttt{.times} file to reflect the changes.
}
checking the state of the simulation at the end of run, then editing the \textit{job}\texttt{.control} 
file and changing the parameters \texttt{dt}, \texttt{max\_time} and \texttt{max\_steps} to suitable values.
Do \underline{not} run \texttt{e3prep.py} again, else it will write all over the \textit{job}.times file
that you need to retain and your newly edited \textit{job}\texttt{.control} file.
At this point, you should be ready to run the main simulation program again.
Remember to supply the relevant \texttt{tindx} value on the command line for your restart.
For example:\\
\texttt{\$ e3shared.exe --job=name --tindx=5 --run}

\medskip
Also, with restarts, be careful that you have consistent modelling requirements and settings.
Restarting a laminar simulation as a turbulent simulation with the $k-\omega$ model would lead
to inconsistent data.
It may be better to start a new job and use \texttt{ExistingSolution} objects 
(see Section\,\ref{sec:ExistingSolution}) to pick up the old data. 
Note that your old and new soltions need to have consistent data, such as number of chemical species, etc.
\texttt{ExistingSolution} works with the data available in the old solution and 
is not smart enough to fill in missing values.

% \newpage
\subsection{Postprocessing (with e3post.py)}\index{postprocessing} 
\label{sec:e3post}
%
Postprocessing of the simulation data is the most unstructured of the simulation activities.
We provide a postprocessing program, \texttt{e3post.py} that has the basic capabilities of picking up 
the simulation data and writing flow field files in formats suitable for 
\texttt{Paraview}, \texttt{Visit}, \texttt{Tecplot}, the venerable \texttt{Plot3D} or 
\texttt{gnuplot}\footnote{See the web sites  \url{http://www.paraview.org}, \url{https://wci.llnl.gov/codes/visit/},
\url{http://www.tecplot.com}, \url{http://people.nas.nasa.gov/\~rogers/plot3d/intro.html} and \url{http://www.gnuplot.info}}.
\vspace{0.25cm} \\
\centerline{\includegraphics[width=0.7\textwidth]{figs/post-process.pdf}}\\

\medskip
To reformat the flow solution data into one unstructured grid
containing all of the flow data for the domain and write this data in a format suitable
for \texttt{Paraview} or \texttt{Visit}, use the command:\\
\texttt{\$ e3post.py --job=\textit{job} --vtk-xml --tindx=all}\\ \index{e3post.py!using}

\medskip
The postprocessing program (\texttt{e3\_post.py}) started as a fairly simple script that picked up solution data
and reformatted it for plotting, however, it has continued to sprout features and has become a bit 
complex to describe.
To see its command-line options, just run it without any options at all.
It should then print a \textit{usage} message which provides some hints.
As of 1$^{st}$ August 2015, this message is:

\noindent
{\footnotesize
\begin{verbatim}
Begin e3post.py...
Source code revision string:  245f2e1c2af4+ 2320+ default tip

Usage:
e3post.py [--help] [--job=<jobFileName>] [--tindx=<index|9999|last|all|xxxx>]
          [--zip-files|--no-zip-files]
          [--moving-grid]
          [--omegaz="[omegaz0,omegaz1,...]"]

          [--add-pitot-p] [--add-total-p] [--add-mach] [--add-total-enthalpy]
          [--add-molef --gmodel-file="gas-model.lua"]
          [--add-number-density --gmodel-file="gas-model.lua"]
          [--add-transport-coeffs --gmodel-file="gas-model.lua"]
          [--add-user-computed-vars="user-script.py"]

          [--vtk-xml] [--binary-format] [--tecplot] [--plot3d] [--OpenFoam]

          [--output-file=<profile-data-file>]
          [--slice-list="blk-range,i-range,j-range,k-range;..."]
          [--slice-at-point="blk-range,index-pair,x,y,z;..."]
          [--slice-along-line="x0,y0,z0,x1,y1,z1,N"]
          [--surface-list="blk,surface-name;..."]
          [--local-surface-list="blk,surface-name;..."]

          [--static-flow-profile="blk,face-name;..."]

          [--heat-flux-list="blk-range,surf-range,i-range,j-range,k-range;..."]
          [--bc-surface-list="blk-range,surf-range,i-range,j-range,k-range;..."]
          [--tangent-slab-list="blk-range,i-range,j-range,k-range;..."]

          [--probe="x,y,z;..."]

          [--report-norms]
          [--per-block-norm-list="jb,var-name,norm-name;..."
          [--global-norm-list="var-name,norm-name;..."
          [--ref-function=<python-script>]
          [--compare-job=<jobFileName> [--compare-tindx=<index>]]

          [--prepare-restart] [--prepare-fstc-restart]
          [--put-into-folders]

          [--verbosity=<int>]

For further information, see the online documentation, the Eilmer3 User Guide
and the source code.
\end{verbatim}
} % end of \footnotesize

\noindent
The options can be combined in fairly complex ways; some experimentation on the part of the user
may be required to get the desired effect.
These can be divided into a number of subsets.
Data loading options:
\begin{itemize}
  \item \texttt{--help} just prints the usage message.  No other options are relevant.
  \item \texttt{--job=<jobFileName>} specifies the root name of the solution files
  \item \texttt{--tindx=<index|9999|last|all|xxxx>} You may pick up one solution time via its numeric index or you may
     specify all solution times via the keyword ``\texttt{all}''. 
     The last solution frame written (and identified in the \textit{job}.times file) can be specified by giving
     the index as ``\texttt{last}'' or as ``\texttt{9999}''.
     If the simulation is run and a special solution frame was written at a particular time step, 
     that solution frame not part of the standard sequence but accessible as index ``\texttt{xxxx}''.
  \item \texttt{--zip-files|--no-zip-files} The default behaviour is to use gzipped files for the
     grid and flow data files, however, earlier version of the code used plain text files that were not zipped.
  \item \texttt{--moving-grid} The default behaviour is to use a fixed grid (defined at \texttt{tindx=0}) for all
     solution frames.
     This flag indicates each solution frame has a dedicated grid that may change from the \texttt{tindx=0} grid.
  \item \texttt{--omegaz} Specify the angular velocities of the rotating-frame grids (if they any non-zero values).
\end{itemize}
Data addition options:
\begin{itemize}
  \item \texttt{--add-pitot-p}, \texttt{--add-total-p}, \texttt{--add-mach} and \texttt{--add-total-enthalpy} add the
     named variable to the plotting data set, either for the full field (VTK, Tecplot and Plot3D format) or for sliced data.
     These flow variables are not in the Eilmer3 native flow solution file and must be reconstructed by \texttt{e3post.py}.
  \item \texttt{--add-molef} Add species mole fractions to the data set.
  \item \texttt{--gmodel-file="gas-model.lua"} To add some of the mole-fractions, the gas model needs to
     be available.  You can use this option to specify the correct gas model file if it is not the default name.
  \item \texttt{--add-number-density} Add number densities for each species to the data set. Please note that the unit is $m^{-3}$, instead of $cm^{3}$ preferred by some radiation modelling codes. Similar to the case of adding mole-frations, the name of the gas model file needs to be specified if it's not the default one.
\end{itemize}
Whole-field output options:
\begin{itemize}
  \item \texttt{--vtk-xml} The XML format for the Visualization Tool Kit (VTK) is readable by both \texttt{Paraview}
     and \texttt{Visit}.  By default, the XML file will be simple text and probably quite large.
  \item \texttt{--binary-format} Write most of the data in the VTK file as appended binary records.
     This makes the files nonconforming XML files but it surely reduces the size of large data files and
     improves the speed of loading them into Paraview.  For large 3D datasets, this is a good option.
  \item \texttt{--tecplot} This produces an ASCII file that can be read by \texttt{Tecplot}.
  \item \texttt{--plot3d} This is also an ASCII format file that many visualization and flow simulation
     packages read and write.
     Two grid files are generated.  The first, with \texttt{.grd} extension, 
     is the true grid as used by the simulation with mesh location at the nodes.  
     The second, with extension \texttt{.g}, has cell-centred values and accompanies 
     the cell-centred values in the \texttt{.f} file.
  \item \texttt{--OpenFoam} This produces files usable in an OpenFOAM simulation.
     It may be convenient to use our grid preparation tools (e3prep with Python script input)
     to assemble a suitable set of grids and initial flow states but then run the simulation
     with the \textit{other} CFD solver \url{http://www.openfoam.org/} but, being biased,
     we wouldn't really like to talk about that here.
\end{itemize}
Data slicing and dicing options:
\begin{itemize}
  \item \texttt{--output-file=<profile-data-file>} specifies the name of a file in which to dump the requested data.
     This naming option is relevant to the various slice options and also to the the surface-list option 
     where it is used as the root name of the generated VTK files.
     This will allow you to make a number of sliced data sets for plotting.
  \item \texttt{--slice-list="blk-range,i-range,j-range,k-range;..."} allows one to extract subsets of the data.
     A Python-like slicing notation is used in the specification string which should be enclosed in quotes, as shown. 
     Several slices (separated by semicolons) may be specified in the one string.
     Each slice specification consists of 4 indices or index ranges separated by commas.  
     An index is a single integer value and may be negative to indicate counting from the end.
     A value of \texttt{-1} indicates the maximum value.
     An index range may be a colon-separated pair of integers, a colon and one limit 
     or just a colon by itself (to indicate the full range).
     Note that the range limits are inclusive.
     So, for example, to extract the EAST strip of cells from block 0 in a 2D simulation, you would use
     the string \texttt{"0,-1,:,0"}.
  \item \texttt{--slice-at-point="blk-range,index-pair,x,y,z;..."} allows one to extract a slice/plane of data
     through a particular point.
     The index-pair is one of ij, jk or ki.  
     The program sets these indices to zero and searches along the remaining index to find the cell nearest 
     the specified (x,y,z) point.
     Once found, the slice over the index pair is selected for output (by adding it to the slice-list).
     Be aware that, for each block selected, slice-at-point will always select a slice to output, 
     even if it is not very close.
     Again, use quotes to hold the string together as it passed through the shell interpreter.
  \item \texttt{--slice-along-line="x0,y0,z0,x1,y1,z1,N"} generates a list of \texttt{N} sampled points between
     the specified end points.
     The sampled data is taken from the nearest cell-centre for eash sample point.
     No higher-order interpolation is done.
  \item \texttt{--surface-list="blk,surface-name;..."} extracts a set of surfaces from the full flow field and 
     writes them as VTK files.  
     Sometimes we want convenient access to the bounding surfaces of the blocks.
     Use \texttt{NORTH}, \texttt{EAST}, \texttt{SOUTH}, \texttt{WEST}, \texttt{TOP} and \texttt{BOTTOM} 
     as the surface names.
  \item \texttt{--probe="x,y,z;..."} reports the sampled data for the specified points.
     The selected data is written in gnuplot format.
  \item \texttt{--heat-flux-list="blk-range,surf-range,i-range,j-range,k-range;..."}\,\footnote{Dan Potter's heat flux code writes
     the heat fluxes for a collection of surfaces.  This was part of his PhD work.} extracts surface heat flux and cell Reynolds number data.
     The syntax is the same as the \texttt{--slice-list} option except that the second argument is the boundary index 
     (\texttt{NORTH}, \texttt{EAST}, \texttt{SOUTH}, \texttt{WEST}, \texttt{TOP} or \texttt{BOTTOM}).
     For 2D simulations, the block and boundary indices are sufficient to define the edge, 
     so you can then leave the \texttt{i-range}, \texttt{j-range} and \texttt{k-range} arguments blank.
     For 3D simulations you would need to specify either \texttt{i}, \texttt{j} or \texttt{k} to get a single line of cells.
     For any range, it is sufficient to give just a colon to get the full range.
     For the surface range, the order of the boundary names comes into play with \texttt{NORTH}=0 and \texttt{BOTTOM}=5.
\end{itemize}
Data manipulation and summary options:
\begin{itemize}
  \item \texttt{--ref-function=<python-script>} compares the flow solution with a supplied Python function.
     The difference is output.
  \item \texttt{--report-norms} returns a dictionary of norms for all of the flow variables.
    The available norms are \texttt{L1}, \texttt{L2}, and \texttt{Linf} (maximum magnitude).
  \item \texttt{--per-block-norm-list="jb,var-name,norm-name;..."} returns the specified norms 
     for particular variables and blocks.  Sometimes just a little bit of information is required.
  \item \texttt{--global-norm-list="var-name,norm-name;..."} returns the specified norms,
     computed over the whole flow domain.
  \item \texttt{--compare-job=<jobFileName> [--compare-tindx=<index>]} compares one flow data set with another.
     The difference is output.  This option combined with the computation of norms is a convenient way to check
     convergence of a simulation.
\end{itemize}
Other house-keeping options for continuing old simulations:
\begin{itemize}
  \item \texttt{--prepare-restart} does some house-keeping in the data files so that a simulation 
     may be restarted cleanly.  
     This is mainly dealing with the old \texttt{9999} file and adjusting the \texttt{.times} file.
     As of April 2013, the \texttt{9999} solution frame is no longer written.
  \item \texttt{--put-into-folders} puts an old solution (which has its files all sitting in the current directory)
     into the current directory structure where the grid, flow and plot files have their own subdirectories.
     Again, this relates to a very old arrangement for the solution files.
\end{itemize}
Note that you must use double-quotes on some specification strings to prevent the command shell 
from pulling the string apart (or otherwise changing it) before giving it to \texttt{e3post.py}.
It is also worth noting that, by default, \verb!e3post.py! does not write anything to the console while it
it running successfully.
If you want more commentary while it is doing its work, supply a nonzero integer to the option \verb!--verbosity!.
A value of 1 should give you a brief summary of the main activities whereas a value of 2 will prompt many more
messages.

\medskip 
Ad hoc postprocessing\index{postprocessing!customized} is possible by picking up the cell-centre flow
data with your own custom postprocessing program written in Python.
Two Python modules (\texttt{e3\_flow.py}\index{module!e3\_flow.py} and \texttt{e3\_grid.py}\index{module!e3\_grid.py}) 
are available for picking up individual blocks of data and storing
selected flow properties in numpy arrays.
Note that three-dimensional arrays are always used, even for two-dimensional simulations
where the k-index has the single value 0.
The examples that make up the bulk of this manual show some of the things that are possible.
Some specific applications of writing a custom postprocessing script are:
\begin{itemize}
 \item estimating the angle of the shock in the axisymmetric flow over a cone (Sec.~\ref{cone20-simple-sec})
 \item the estimation of surface force on the 10$^o$ ramp case (Sec.~\ref{simple-ramp-sec}) and
 \item finding the location of the bow shock for the finite cylinder simulation (Sec.~\ref{sec:finite-cyl-sec}).
\end{itemize}
 

\subsection{Supervisory GUI}
%
To ease new-comers into the use of the codes, the \texttt{e3console.tcl} program provides
a graphical view of the simulation process.
It provides straight-forward automation of the simple case of running a simulation
from scratch and then reformatting the entire flow-field data for plotting.
Figure\,\ref{e3console-screenshot-fig} shows the state of the GUI just after running the
cone20 simulation.
The Python input file is shown in the top text frame of the main window, 
with the log of the standard output from the simulation shown in the lower text frame.
The tab for the postprocessor is visible in the ``Options'' window.
It indicates that \texttt{e3post.py} will reformat all the flow data into the XML
file format for the VTK plotting library (as used by Paraview).
Also, note the text in the console window which shows the underlying commands that have been used. 

\begin{figure}
 \includegraphics[width=\textwidth]{figs/e3console-screenshot.png}
 \caption{Screen shot of the \texttt{e3console.tcl} GUI running on PJ's workstation.}
 \label{e3console-screenshot-fig}
\end{figure}

\clearpage
